{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitnlpconda2c54c4d051734952b5238f4efd68fcff",
   "display_name": "Python 3.6.8 64-bit ('NLP': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用FastText的監督式學習方法進行文本分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,jieba,random\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_dic = {'Car News':1, 'Entertainment News':2, 'International News':3, 'Technology News':4, 'Society News':5, 'Sports News':6, 'Finance News':7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Car News:11740\nEntertainment News:39264\nInternational News:89338\nTechnology News:25057\nSociety News:268829\nSports News:32728\nFinance News:143141\n\n"
    }
   ],
   "source": [
    "#讀取分類的檔案\n",
    "car_news = pd.read_csv('class_data/car_news.csv',encoding='utf-8')\n",
    "car_news = car_news.dropna()\n",
    "\n",
    "entertainment_news = pd.read_csv('class_data/entertainment_news.csv',encoding='utf-8')\n",
    "entertainment_news = entertainment_news.dropna()\n",
    "\n",
    "international_news = pd.read_csv('class_data/international_news.csv',encoding='utf-8')\n",
    "international_news = international_news.dropna()\n",
    "\n",
    "technology_news = pd.read_csv('class_data/technology_news.csv',encoding='utf-8')\n",
    "technology_news = technology_news.dropna()\n",
    "\n",
    "society_news = pd.read_csv('class_data/society_news.csv',encoding='utf-8')\n",
    "society_news = society_news.dropna()\n",
    "\n",
    "sports_news = pd.read_csv('class_data/sports_news.csv',encoding='utf-8')\n",
    "sports_news = sports_news.dropna()\n",
    "\n",
    "finance_news = pd.read_csv('class_data/finance_news.csv',encoding='utf-8')\n",
    "finance_news = finance_news.dropna()\n",
    "\n",
    "print('Car News:{}\\nEntertainment News:{}\\nInternational News:{}\\nTechnology News:{}\\nSociety News:{}\\nSports News:{}\\nFinance News:{}\\n'.format(len(car_news),len(entertainment_news),len(international_news),len(technology_news),len(society_news),len(sports_news),len(finance_news)))\n",
    "\n",
    "#每個新聞取出8000筆\n",
    "car_news = car_news[:10000]\n",
    "entertainment_news = entertainment_news[:10000]\n",
    "entertainment_news = entertainment_news[:10000]\n",
    "technology_news = technology_news[:10000]\n",
    "society_news = society_news[:10000]\n",
    "sports_news = sports_news[:10000]\n",
    "finance_news = finance_news[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list=[]\n",
    "with open('data/stopwords.txt','r',encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        stop_list.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Building prefix dict from the default dictionary ...\nLoading model from cache /var/folders/vk/4wfw6yvn67b0gpkhvj8wy0cw0000gn/T/jieba.cache\nLoading model cost 1.559 seconds.\nPrefix dict has been built succesfully.\n"
    }
   ],
   "source": [
    "def preprocess(data,all_data,category):\n",
    "    for line in data:\n",
    "        line = re.sub(r'[^\\w]','',line)\n",
    "        line = re.sub(r'[A-Za-z0-9]','',line)\n",
    "        line = re.sub(u'[\\uFF01-\\uFF5A]','',line)\n",
    "        segment_list = jieba.lcut(line)\n",
    "        segment_list = filter(lambda x: len(x)>1,segment_list)\n",
    "        segment_list = filter(lambda x: x not in stop_list,segment_list)\n",
    "        all_data.append( \"__label__\"+str(cate_dic[category])+\" , \"+\" \".join(segment_list) )\n",
    "\n",
    "all_data = []\n",
    "preprocess(car_news.content.values.tolist(),all_data,'Car News')\n",
    "preprocess(technology_news.content.values.tolist(),all_data,'Entertainment News')\n",
    "preprocess(technology_news.content.values.tolist(),all_data,'International News')\n",
    "preprocess(technology_news.content.values.tolist(),all_data,'Technology News')\n",
    "preprocess(society_news.content.values.tolist(),all_data,'Society News')\n",
    "preprocess(sports_news.content.values.tolist(),all_data,'Sports News')\n",
    "preprocess(finance_news.content.values.tolist(),all_data,'Finance News')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按照7:3切分訓練與測試資料集\n",
    "\n",
    "random.shuffle(all_data)\n",
    "train_data = all_data[:int(len(all_data)*0.8)]\n",
    "test_data = all_data[int(len(all_data)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Writing data to fasttext format...\ndone!\n"
    }
   ],
   "source": [
    "# 儲存訓練與測試資料集檔案\n",
    "\n",
    "print(\"Writing data to fasttext format...\")\n",
    "\n",
    "with open('data/fasttext_train_data.txt', 'w',encoding='utf-8') as f:\n",
    "    for data in train_data:\n",
    "        f.write(data+\"\\n\")\n",
    "f.close()\n",
    "\n",
    "with open('data/fasttext_test_data.txt', 'w',encoding='utf-8') as f2:\n",
    "    for data in test_data:\n",
    "        f2.write(data+\"\\n\")\n",
    "f2.close()\n",
    "\n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Help on function train_supervised in module fasttext.FastText:\n\ntrain_supervised(*kargs, **kwargs)\n    Train a supervised model and return a model object.\n    \n    input must be a filepath. The input text does not need to be tokenized\n    as per the tokenize function, but it must be preprocessed and encoded\n    as UTF-8. You might want to consult standard preprocessing scripts such\n    as tokenizer.perl mentioned here: http://www.statmt.org/wmt07/baseline.html\n    \n    The input file must must contain at least one label per line. For an\n    example consult the example datasets which are part of the fastText\n    repository such as the dataset pulled by classification-example.sh.\n\n"
    }
   ],
   "source": [
    "help(fasttext.train_supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Precision:0.6879107142857143\nRecall:0.6879107142857143\nNumber of examples:56000\n"
    }
   ],
   "source": [
    "# 訓練FastText模型\n",
    "classifier = fasttext.train_supervised('data/fasttext_train_data.txt')\n",
    "result = classifier.test('data/fasttext_test_data.txt')\n",
    "print('Precision:{}'.format(result[1]))\n",
    "print('Recall:{}'.format(result[2]))\n",
    "print('Number of examples:{}'.format(result[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Car News\t1.0000096559524536\nFinance News\t1.0137071512872353e-05\nSociety News\t1.0123488209501375e-05\n"
    }
   ],
   "source": [
    "recate_dic = {'1':'Car News', '2':'Entertainment News', '3':'International News', '4':'Technology News', '5':'Society News', '6':'Sports News', '7':'Finance News'}\n",
    "result = classifier.predict(['新車 好看 美 等等 一次 付清'],k=3)\n",
    "for n in range(3):\n",
    "    print('{}\\t{}'.format( recate_dic[ result[0][0][n].split('__label__')[1] ],result[1][0][n] ))"
   ]
  }
 ]
}