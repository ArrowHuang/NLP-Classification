{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用SVM進行新聞分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,jieba,random\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.svm import SVC #SVM分類模型\n",
    "from sklearn.model_selection import train_test_split #切割訓練與測試資料\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer #提取詞的特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Car News:11740\nTechnology News:25057\nSociety News:268829\nSports News:32728\nFinance News:143141\n\n"
    }
   ],
   "source": [
    "#讀取分類的檔案\n",
    "car_news = pd.read_csv('class_data/car_news.csv',encoding='utf-8')\n",
    "car_news = car_news.dropna()\n",
    "\n",
    "technology_news = pd.read_csv('class_data/technology_news.csv',encoding='utf-8')\n",
    "technology_news = technology_news.dropna()\n",
    "\n",
    "society_news = pd.read_csv('class_data/society_news.csv',encoding='utf-8')\n",
    "society_news = society_news.dropna()\n",
    "\n",
    "sports_news = pd.read_csv('class_data/sports_news.csv',encoding='utf-8')\n",
    "sports_news = sports_news.dropna()\n",
    "\n",
    "finance_news = pd.read_csv('class_data/finance_news.csv',encoding='utf-8')\n",
    "finance_news = finance_news.dropna()\n",
    "\n",
    "print('Car News:{}\\nTechnology News:{}\\nSociety News:{}\\nSports News:{}\\nFinance News:{}\\n'.format(len(car_news),len(technology_news),len(society_news),len(sports_news),len(finance_news)))\n",
    "\n",
    "#每個新聞取出8000筆\n",
    "car_news = car_news[:8000]\n",
    "technology_news = technology_news[:8000]\n",
    "society_news = society_news[:8000]\n",
    "sports_news = sports_news[:8000]\n",
    "finance_news = finance_news[:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_list=[]\n",
    "with open('data/stopwords.txt','r',encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        stop_list.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Building prefix dict from the default dictionary ...\nLoading model from cache /var/folders/vk/4wfw6yvn67b0gpkhvj8wy0cw0000gn/T/jieba.cache\nLoading model cost 1.505 seconds.\nPrefix dict has been built successfully.\n"
    }
   ],
   "source": [
    "def preprocess(data,all_data,category):\n",
    "    for line in data:\n",
    "        line = re.sub(r'[^\\w]','',line)\n",
    "        line = re.sub(r'[A-Za-z0-9]','',line)\n",
    "        line = re.sub(u'[\\uFF01-\\uFF5A]','',line)\n",
    "        segment_list = jieba.lcut(line)\n",
    "        segment_list = filter(lambda x: len(x)>1,segment_list)\n",
    "        segment_list = filter(lambda x: x not in stop_list,segment_list)\n",
    "        all_data.append( (' '.join(segment_list),category) )\n",
    "\n",
    "all_data = []\n",
    "preprocess(car_news.content.values.tolist(),all_data,'Car News')\n",
    "preprocess(technology_news.content.values.tolist(),all_data,'Technology News')\n",
    "preprocess(society_news.content.values.tolist(),all_data,'Society News')\n",
    "preprocess(sports_news.content.values.tolist(),all_data,'Sports News')\n",
    "preprocess(finance_news.content.values.tolist(),all_data,'Finance News')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(all_data) #將所有資料打亂順序\n",
    "x,y = zip(*all_data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n                dtype=<class 'numpy.float64'>, encoding='utf-8',\n                input='content', lowercase=True, max_df=1.0, max_features=8000,\n                min_df=1, ngram_range=(1, 4), norm='l2', preprocessor=None,\n                smooth_idf=True, stop_words=None, strip_accents=None,\n                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                tokenizer=None, use_idf=True, vocabulary=None)"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# 詞袋模型提取特徵\n",
    "vec = CountVectorizer(\n",
    "    analyzer='word', # 特徵由單詞構成\n",
    "    ngram_range=(1,4), # ngram取1gram到4gram\n",
    "    max_features=8000 # 選最常出現400個單詞構成詞袋\n",
    ")\n",
    "vec.fit(x_train)\n",
    "\n",
    "# TFIDF模型提取特徵\n",
    "tvec = TfidfVectorizer(\n",
    "    analyzer='word', # 特徵由單詞構成\n",
    "    ngram_range=(1,4), # ngram取1gram到4gram\n",
    "    max_features=8000 # 選最常出現400個單詞構成詞袋\n",
    ")\n",
    "tvec.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7448333333333333"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# 訓練並測試模型(提取特徵用詞袋)\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(vec.transform(x_train),y_train)\n",
    "svm_model.score(vec.transform(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7920833333333334"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# 訓練並測試模型(提取特徵用TFIDF)\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(tvec.transform(x_train),y_train)\n",
    "svm_model.score(tvec.transform(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉驗證函式\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score,recall_score,precision_score\n",
    "def K_Fold_Validation(x_d,y_d,k,classifier):\n",
    "    stratifiedkfold = StratifiedKFold(n_splits=k,shuffle=True)\n",
    "    x_tem = tvec.transform(x_d)\n",
    "    y_tem = np.array(y_d)\n",
    "    y_ref = y_tem[:]\n",
    "    for train_index, test_index in stratifiedkfold.split(x_tem,y_tem):\n",
    "        x_tra, x_tes = x_tem[train_index], x_tem[test_index]\n",
    "        y_tra = y_tem[train_index]\n",
    "        cl = classifier\n",
    "        cl.fit(x_tra,y_tra)\n",
    "        y_ref[test_index] = cl.predict(x_tes)\n",
    "\n",
    "    print('Accuracy: {}'.format( accuracy_score(y_d,y_ref) ))\n",
    "    print('Precision: {}'.format( precision_score(y_d,y_ref,average='macro') ))\n",
    "    print('Recall: {}'.format( recall_score(y_d,y_ref,average='macro') ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.8042\nPrecision: 0.817889455764005\nRecall: 0.8042\n"
    }
   ],
   "source": [
    "K_Fold_Validation(x,y,5,SVC(kernel='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 封裝成Class\n",
    "class SVM_Classification():\n",
    "    def __init__(self,classifier=SVC(kernel='linear')):\n",
    "        self.classifier = classifier\n",
    "        self.vectorizer = TfidfVectorizer( analyzer='word', ngram_range=(1,4), max_features=8000 )\n",
    "\n",
    "    def features(self,x):\n",
    "        return self.vectorizer.transform(x)\n",
    "    \n",
    "    def fit(self,x_train,y_train):\n",
    "        self.vectorizer.fit(x_train)\n",
    "        self.classifier.fit(self.features(x_train),y_train)\n",
    "    \n",
    "    def predict(self,x_test):\n",
    "        return self.classifier.predict(self.features([x_test]))\n",
    "\n",
    "    def score(self,x_test,y_test):\n",
    "        return self.classifier.score(self.features(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Car News']\n0.7920833333333334\n"
    }
   ],
   "source": [
    "svm_classifier = SVM_Classification()\n",
    "svm_classifier.fit(x_train,y_train)\n",
    "print(svm_classifier.predict('汽車 很新 好看'))\n",
    "print(svm_classifier.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用決策樹進行新聞分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.65"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# 訓練並測試模型(提取特徵用詞袋)\n",
    "decisionT_model = DecisionTreeClassifier()\n",
    "decisionT_model.fit(vec.transform(x_train),y_train)\n",
    "decisionT_model.score(vec.transform(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6320833333333333"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# 訓練並測試模型(提取特徵用TFIDF)\n",
    "decisionT_model = DecisionTreeClassifier(criterion='entropy') \n",
    "decisionT_model.fit(tvec.transform(x_train),y_train)\n",
    "decisionT_model.score(tvec.transform(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.69065\nPrecision: 0.6908407196023715\nRecall: 0.69065\n"
    }
   ],
   "source": [
    "# K-Fold交叉驗證\n",
    "K_Fold_Validation(x,y,5,DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用隨機森林進行新聞分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.73725"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# 訓練並測試模型(提取特徵用詞袋)\n",
    "randomFR_model = RandomForestClassifier(n_estimators=1000,criterion='gini')\n",
    "randomFR_model.fit(vec.transform(x_train),y_train)\n",
    "randomFR_model.score(vec.transform(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.74025"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# 訓練並測試模型(提取特徵用TFIDF)\n",
    "randomFR_model = RandomForestClassifier(n_estimators=1000,criterion='entropy')\n",
    "randomFR_model.fit(tvec.transform(x_train),y_train)\n",
    "randomFR_model.score(tvec.transform(x_test),y_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bitnlpconda2c54c4d051734952b5238f4efd68fcff",
   "display_name": "Python 3.6.8 64-bit ('NLP': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}